{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatRitchie/Sunshine/blob/main/PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGE4DFSBPGkN"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rzXZQhcqMOqi"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata, files\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwZpYyGNNUE"
      },
      "source": [
        "Acces github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRTBa3b5NL8B",
        "outputId": "baaac05e-5256-4f66-aad4-d4ae3437f62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'Sunshine' already exists and is not an empty directory.\n",
            "/content/Sunshine\n",
            "From https://github.com/MatRitchie/Sunshine\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "os.environ['GITHUB_TOKEN'] = userdata.get('GITHUB_TOKEN')\n",
        "%cd /content\n",
        "!git clone https://$GITHUB_TOKEN@github.com/MatRitchie/Sunshine.git\n",
        "\n",
        "%cd /content/Sunshine\n",
        "!git pull https://$GITHUB_TOKEN@github.com/MatRitchie/Sunshine.git main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ovq_JBBnLi4b"
      },
      "outputs": [],
      "source": [
        "FILES = {\n",
        "    \"evolved\": \"incubator_project_graduated_from_graduation.csv\",\n",
        "    \"retired\": \"incubator_project_metrics_graduated_retired.csv\",\n",
        "    \"bypassed\": \"non_incubator_project_metrics.csv\"\n",
        "}\n",
        "OUTPUT_FILE = \"combined_project_status.csv\"\n",
        "\n",
        "LABELS = [\n",
        "    'project', 'COM-1', 'COM-3', 'POP-4', 'STA-1', 'STA-2', 'STA-4', 'STA-5',\n",
        "    'STA-6', 'STA-7', 'STA-10', 'STA-11', 'STA-12', 'TEC-1', 'TEC-2.1',\n",
        "    'TEC-2.2', 'TEC-2.3', 'TEC-2.4', 'TEC-4', 'TEC-5', 'SWQ-1', 'SWQ-4.1',\n",
        "    'SWQ-4.2', 'SWQ-4.3', 'SWQ-4.4', 'SWQ-4.5', 'SWQ-4.6', 'SWQ-4.7',\n",
        "    'init', 'end', 'frequency (weeks)', 'project_url'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49VjZBqlMMre"
      },
      "source": [
        "##Load and process the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taAMaZ1gMQmv",
        "outputId": "95b0c229-48f6-463c-baa0-e45a4c614c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing file for status: evolved, path: incubator_project_graduated_from_graduation.csv\n",
            "  Number of DATA ROWS read by pandas for 'evolved': 222\n",
            "  Number of rows for 'evolved' after processing in loop: 222\n",
            "\n",
            "Processing file for status: retired, path: incubator_project_metrics_graduated_retired.csv\n",
            "  Number of DATA ROWS read by pandas for 'retired': 282\n",
            "  Number of rows for 'retired' after processing in loop: 282\n",
            "\n",
            "Processing file for status: bypassed, path: non_incubator_project_metrics.csv\n",
            "  Number of DATA ROWS read by pandas for 'bypassed': 114\n",
            "  Total lines in the actual file 'non_incubator_project_metrics.csv': 115\n",
            "  Content of the first few rows read by pandas for 'bypassed':\n",
            "    ant-antlibs-dotnet      Issues missing Issues missing.1     17  \\\n",
            "0                  ant      Issues missing   Issues missing   1256   \n",
            "1  ant-antlibs-antunit      Issues missing   Issues missing     30   \n",
            "2                arrow   6105807.218980744           172658  31660   \n",
            "3                 avro   6462805.389824351            24414   7343   \n",
            "4                camel  3466323.3808316793            73584  15833   \n",
            "\n",
            "   2014-05-28 07:00:08    3     7 PRs missing   1   True  ...  3.1 0.2  0.3  \\\n",
            "0  2014-05-28 07:00:08   34   426           1   3  False  ...    4   2   12   \n",
            "1  2014-05-28 07:00:07    4    14           0   1   True  ...    0   0    0   \n",
            "2  2016-02-17 08:00:23 -414  3440         -69  16  False  ...    0  40  120   \n",
            "3  2009-05-21 02:48:37 -154  1609          62   5  False  ...   19   1   13   \n",
            "4  2009-05-21 00:25:36 -551  4923         332   4  False  ...    0  24   36   \n",
            "\n",
            "   0.4  4.003813155386082   60  2014-05-28  2019-05-26  12  \\\n",
            "0   36          12.696530  217  2014-05-28  2024-08-18  12   \n",
            "1    0          15.920826   38  2014-05-28  2022-02-13  12   \n",
            "2  155          16.830452  500  2016-02-17  2024-08-23  12   \n",
            "3   28          10.676941  155  2009-05-21  2024-08-22  12   \n",
            "4  145          16.844756  482  2009-05-21  2024-08-22  12   \n",
            "\n",
            "    https://github.com/apache/ant-antlibs-dotnet  \n",
            "0                  https://github.com/apache/ant  \n",
            "1  https://github.com/apache/ant-antlibs-antunit  \n",
            "2                https://github.com/apache/arrow  \n",
            "3                 https://github.com/apache/avro  \n",
            "4                https://github.com/apache/camel  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "  Number of rows for 'bypassed' after processing in loop: 114\n"
          ]
        }
      ],
      "source": [
        "dfs = {}\n",
        "for status, filepath in FILES.items():\n",
        "    try:\n",
        "        print(f\"\\nProcessing file for status: {status}, path: {filepath}\") \n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"  Number of DATA ROWS read by pandas for '{status}': {len(df)}\") \n",
        "\n",
        "        if status == \"bypassed\":\n",
        "            with open(filepath, 'r') as f_temp:\n",
        "                num_lines_in_file = sum(1 for line_in_f in f_temp)\n",
        "            print(f\"  Total lines in the actual file '{filepath}': {num_lines_in_file}\")\n",
        "            print(f\"  Content of the first few rows read by pandas for '{status}':\\n{df.head()}\")\n",
        "\n",
        "\n",
        "        df.columns = LABELS[:min(len(df.columns), len(LABELS))]\n",
        "\n",
        "        df.rename(columns={\n",
        "            'COM-1'   : 'COM-1',\n",
        "            'COM-3'   : 'COM-2',\n",
        "            'POP-4'   : 'POP-1',\n",
        "            'STA-1'   : 'STA-1',\n",
        "            'STA-2'   : 'STA-2',\n",
        "            'STA-4'   : 'STA-3',\n",
        "            'STA-5'   : 'STA-4',\n",
        "            'STA-6'   : 'STA-5',\n",
        "            'STA-7'   : 'STA-6',\n",
        "            'STA-10'  : 'STA-7',\n",
        "            'STA-11'  : 'STA-8',\n",
        "            'STA-12'  : 'STA-9',\n",
        "            'TEC-1'   : 'TEC-1',\n",
        "            'TEC-2.4' : 'TEC-2',\n",
        "            'TEC-4'   : 'TEC-3',\n",
        "            'TEC-5'   : 'TEC-4',\n",
        "            'SWQ-1'   : 'SWQ-1',\n",
        "            'SWQ-4.1' : 'SWQ-2.1',\n",
        "            'SWQ-4.2' : 'SWQ-2.2',\n",
        "            'SWQ-4.3' : 'SWQ-2.3',\n",
        "            'SWQ-4.4' : 'SWQ-2.4',\n",
        "            'SWQ-4.5' : 'SWQ-2.5',\n",
        "            'SWQ-4.6' : 'SWQ-2.6',\n",
        "            'SWQ-4.7' : 'SWQ-2.7',\n",
        "        }, inplace=True)\n",
        "\n",
        "        if 'TEC-2.2' in df.columns:\n",
        "          df.drop(columns=['TEC-2.2'], inplace=True)\n",
        "\n",
        "        if 'frequency (weeks)' in df.columns:\n",
        "          df.drop(columns=['frequency (weeks)'], inplace=True)\n",
        "\n",
        "        if 'STA-6' in df.columns:\n",
        "          df['STA-6'] = df['STA-6'].apply(lambda x: 1 if str(x).lower() == 'true' else (0 if str(x).lower() == 'false' else x))\n",
        "\n",
        "        # Calculate project age from STA-1 if its there\n",
        "        if 'STA-1' in df.columns:\n",
        "            df['STA-1'] = (2025 - pd.to_datetime(df['STA-1'], errors='coerce').dt.year).fillna(-1).astype(int)\n",
        "\n",
        "        df['status'] = status\n",
        "        dfs[status] = df\n",
        "        print(f\"  Number of rows for '{status}' after processing in loop: {len(df)}\") \n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filepath}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3qtw-xVMWcQ"
      },
      "source": [
        "# Set project status based on presence in evolved list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GLXdZPHfMYD4"
      },
      "outputs": [],
      "source": [
        "if 'evolved' in dfs and 'retired' in dfs:\n",
        "    evolved_projects = set(dfs['evolved']['project'])\n",
        "    dfs['retired']['status'] = dfs['retired']['project'].apply(\n",
        "        lambda proj: 'graduated' if proj in evolved_projects else 'retired'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk7TK_aAMpaG",
        "outputId": "0825a32c-f72e-4dba-d069-6986e6b9ccaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Counts per status in df_combined (raw, after concat, before any filtering in this cell) ---\n",
            "status\n",
            "evolved      222\n",
            "graduated    222\n",
            "bypassed     114\n",
            "retired       60\n",
            "Name: count, dtype: int64\n",
            "Is 'fluo-yarn' present in df_combined at this stage? True\n",
            "Status of 'fluo-yarn' in df_combined: ['bypassed']\n",
            "Shape of df_combined: (618, 31)\n",
            "--- End of initial df_combined stats ---\n",
            "\n",
            "--- Counts per status in df_base_for_row_removal_stats (after column dropna, before fluo-yarn/row removal) ---\n",
            "status\n",
            "evolved      222\n",
            "graduated    222\n",
            "bypassed     114\n",
            "retired       60\n",
            "Name: count, dtype: int64\n",
            "Is 'fluo-yarn' present in df_base_for_row_removal_stats? True\n",
            "Status of 'fluo-yarn' in df_base_for_row_removal_stats: ['bypassed']\n",
            "Shape of df_base_for_row_removal_stats: (618, 29)\n",
            "--- End of df_base_for_row_removal_stats stats ---\n",
            "\n",
            "Removing 'fluo-yarn'...\n",
            "--- Counts per status in final df_clean (after all cleaning) ---\n",
            "status\n",
            "evolved      189\n",
            "graduated    189\n",
            "bypassed      99\n",
            "retired       47\n",
            "Name: count, dtype: int64\n",
            "Is 'fluo-yarn' present in df_clean? False\n",
            "Shape of df_clean: (524, 29)\n",
            "--- End of df_clean stats ---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_combined = pd.concat([df for df in dfs.values() if df is not None], ignore_index=True)\n",
        "\n",
        "print(\"--- Counts per status in df_combined (raw, after concat, before any filtering in this cell) ---\")\n",
        "print(df_combined['status'].value_counts())\n",
        "print(\"Is 'fluo-yarn' present in df_combined at this stage?\", 'fluo-yarn' in df_combined['project'].values)\n",
        "if 'fluo-yarn' in df_combined['project'].values:\n",
        "    print(\"Status of 'fluo-yarn' in df_combined:\", df_combined[df_combined['project'] == 'fluo-yarn']['status'].values)\n",
        "print(\"Shape of df_combined:\", df_combined.shape)\n",
        "print(\"--- End of initial df_combined stats ---\\n\")\n",
        "\n",
        "df_base_for_row_removal_stats = df_combined.dropna(axis=1, how='all').copy()\n",
        "\n",
        "print(\"--- Counts per status in df_base_for_row_removal_stats (after column dropna, before fluo-yarn/row removal) ---\")\n",
        "print(df_base_for_row_removal_stats['status'].value_counts())\n",
        "print(\"Is 'fluo-yarn' present in df_base_for_row_removal_stats?\", 'fluo-yarn' in df_base_for_row_removal_stats['project'].values)\n",
        "if 'fluo-yarn' in df_base_for_row_removal_stats['project'].values:\n",
        "    print(\"Status of 'fluo-yarn' in df_base_for_row_removal_stats:\", df_base_for_row_removal_stats[df_base_for_row_removal_stats['project'] == 'fluo-yarn']['status'].values)\n",
        "print(\"Shape of df_base_for_row_removal_stats:\", df_base_for_row_removal_stats.shape)\n",
        "print(\"--- End of df_base_for_row_removal_stats stats ---\\n\")\n",
        "\n",
        "df_for_cleaning = df_base_for_row_removal_stats.copy()\n",
        "\n",
        "# remove bad project fluo-yarn\n",
        "if 'fluo-yarn' in df_for_cleaning['project'].values:\n",
        "    print(\"Removing 'fluo-yarn'...\")\n",
        "    df_for_cleaning = df_for_cleaning[df_for_cleaning['project'] != 'fluo-yarn']\n",
        "else:\n",
        "    print(\"'fluo-yarn' not found in df_for_cleaning before explicit removal step.\")\n",
        "\n",
        "\n",
        "# remove rows with strings that say \"missing\"\n",
        "df_for_cleaning = df_for_cleaning[~df_for_cleaning.astype(str).apply(lambda x: x.str.contains('missing', case=False, na=False)).any(axis=1)]\n",
        "\n",
        "df_clean = df_for_cleaning.dropna()\n",
        "\n",
        "print(\"--- Counts per status in final df_clean (after all cleaning) ---\")\n",
        "print(df_clean['status'].value_counts())\n",
        "print(\"Is 'fluo-yarn' present in df_clean?\", 'fluo-yarn' in df_clean['project'].values)\n",
        "print(\"Shape of df_clean:\", df_clean.shape)\n",
        "print(\"--- End of df_clean stats ---\\n\")\n",
        "\n",
        "try:\n",
        "    df_clean.to_csv(OUTPUT_FILE, index=False)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving output: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adLf6gWdOZGi"
      },
      "source": [
        "#Missing data removal analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTaSVOUDOdzo",
        "outputId": "de9979b2-6653-4328-db47-b77d77097476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Missing Data Removal Analysis ---\n",
            "\n",
            "Statistics on projects removed (includes 'fluo-yarn', rows with 'missing' text, or NaN data):\n",
            "\n",
            "Overall Project Row Counts:\n",
            "  Total project entries in baseline (before specific removals): 618\n",
            "  Total project entries removed: 94\n",
            "  Total project entries remaining in df_clean: 524\n",
            "  Note: 'fluo-yarn' was among the removed projects. Its status at time of removal consideration was: bypassed\n",
            "\n",
            "Breakdown by project status (based on project entries/rows):\n",
            "\n",
            "Status: bypassed\n",
            "  Number of project entries initially for this status: 114\n",
            "  Number of project entries removed for this status: 15\n",
            "  Number of project entries remaining for this status: 99\n",
            "  Proportion of project entries left for this status: 86.84%\n",
            "\n",
            "Status: evolved\n",
            "  Number of project entries initially for this status: 222\n",
            "  Number of project entries removed for this status: 33\n",
            "  Number of project entries remaining for this status: 189\n",
            "  Proportion of project entries left for this status: 85.14%\n",
            "\n",
            "Status: graduated\n",
            "  Number of project entries initially for this status: 222\n",
            "  Number of project entries removed for this status: 33\n",
            "  Number of project entries remaining for this status: 189\n",
            "  Proportion of project entries left for this status: 85.14%\n",
            "\n",
            "Status: retired\n",
            "  Number of project entries initially for this status: 60\n",
            "  Number of project entries removed for this status: 13\n",
            "  Number of project entries remaining for this status: 47\n",
            "  Proportion of project entries left for this status: 78.33%\n",
            "\n",
            "--- End of Missing Data Removal Analysis ---\n"
          ]
        }
      ],
      "source": [
        "projects_in_baseline = set(df_base_for_row_removal_stats['project'])\n",
        "projects_in_clean = set(df_clean['project'])\n",
        "\n",
        "removed_project_names = projects_in_baseline - projects_in_clean\n",
        "df_removed_projects = df_base_for_row_removal_stats[df_base_for_row_removal_stats['project'].isin(removed_project_names)]\n",
        "counts_of_removed_projects_by_status = df_removed_projects['status'].value_counts()\n",
        "\n",
        "initial_total_counts_by_status = df_base_for_row_removal_stats['status'].value_counts()\n",
        "all_statuses = sorted(list(df_base_for_row_removal_stats['status'].unique()))\n",
        "\n",
        "print(\"\\nStatistics on projects removed (includes 'fluo-yarn', rows with 'missing' text, or NaN data):\")\n",
        "total_projects_in_baseline = len(projects_in_baseline)\n",
        "total_rows_in_baseline = len(df_base_for_row_removal_stats)\n",
        "total_projects_removed = len(removed_project_names) \n",
        "total_rows_removed = len(df_removed_projects)\n",
        "total_projects_remaining = len(projects_in_clean)\n",
        "total_rows_remaining = len(df_clean)\n",
        "\n",
        "print(f\"\\nOverall Project Row Counts:\")\n",
        "print(f\"  Total project entries in baseline (before specific removals): {total_rows_in_baseline}\")\n",
        "print(f\"  Total project entries removed: {total_rows_removed}\")\n",
        "print(f\"  Total project entries remaining in df_clean: {total_rows_remaining}\")\n",
        "\n",
        "print(\"\\nBreakdown by project status (based on project entries/rows):\")\n",
        "for status in all_statuses:\n",
        "    initial_row_count = initial_total_counts_by_status.get(status, 0)\n",
        "    removed_row_count = counts_of_removed_projects_by_status.get(status, 0)\n",
        "\n",
        "    print(f\"\\nStatus: {status}\")\n",
        "    print(f\"  Number of project entries initially for this status: {initial_row_count}\")\n",
        "    print(f\"  Number of project entries removed for this status: {removed_row_count}\")\n",
        "\n",
        "    if initial_row_count > 0:\n",
        "        remaining_row_count = initial_row_count - removed_row_count\n",
        "        proportion_left = remaining_row_count / initial_row_count\n",
        "        print(f\"  Number of project entries remaining for this status: {remaining_row_count}\")\n",
        "        print(f\"  Proportion of project entries left for this status: {proportion_left:.2%}\")\n",
        "    elif removed_row_count > 0:\n",
        "        print(f\"  Warning: {removed_row_count} project entries removed, but initial count for this status was 0 in the baseline. This might indicate an issue or a project changing status before removal consideration.\")\n",
        "    else:\n",
        "        print(f\"  No project entries found for this status in the baseline or among removed.\")\n",
        "\n",
        "print(\"\\n--- End of Missing Data Removal Analysis ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L1wsnI2Nmza"
      },
      "source": [
        "#Pushing processed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wC0eNAZNiLG",
        "outputId": "c8305815-3eac-43ea-a7e4-0562d3dd5f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "# Stage the new files for Git\n",
        "!git add {OUTPUT_FILE}\n",
        "!git commit -m \"Add preprocessed data for combined files with removed missing data\"\n",
        "\n",
        "!git config --global user.email \"auto@example.com\"\n",
        "!git config --global user.name \"Auto\"   \n",
        "\n",
        "!git push https://$GITHUB_TOKEN@github.com/MatRitchie/Sunshine.git main"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
